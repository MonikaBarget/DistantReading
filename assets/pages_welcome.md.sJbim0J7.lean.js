import{_ as t,c as a,a0 as o,o as r}from"./chunks/framework.OEd72lfg.js";const m=JSON.parse('{"title":"Welcome","description":"","frontmatter":{},"headers":[],"relativePath":"pages_welcome.md","filePath":"pages_welcome.md"}'),i={name:"pages_welcome.md"};function s(n,e,c,l,d,h){return r(),a("div",null,e[0]||(e[0]=[o('<h1 id="welcome" tabindex="-1">Welcome <a class="header-anchor" href="#welcome" aria-label="Permalink to &quot;Welcome&quot;">​</a></h1><h2 id="about-me" tabindex="-1">About me <a class="header-anchor" href="#about-me" aria-label="Permalink to &quot;About me&quot;">​</a></h2><p>I am assistant professor in the History department at Maastricht University and specialise in the early modern period and digital humanities. One of my research and teaching interests is computational text analysis, which is why I have created this repository.</p><h2 id="the-distant-reading-repository" tabindex="-1">The distant reading repository <a class="header-anchor" href="#the-distant-reading-repository" aria-label="Permalink to &quot;The distant reading repository&quot;">​</a></h2><p>This repository contains tutorials, data samples and code related to distant reading. In the courses and workshops I currently teach, participants do not have previous training in Natural Language Processing (NLP), which is why the text analysis itself is carried out with <a href="https://voyant-tools.org/" target="_blank" rel="noreferrer">Voyant Tools</a>, &quot;a web-based reading and analysis environment for digital texts&quot;. However, we use Python code for data collection, merging text files and some basic data cleaning. Please check the <a href="https://monikabarget.github.io/distant-reading/pages_datacollection.html" target="_blank" rel="noreferrer">Data Collection</a> and <a href="https://monikabarget.github.io/distant-reading/pages_datacleaning.html" target="_blank" rel="noreferrer">Data Cleaning</a> sections for detail.</p><h2 id="machines-of-knowledge-course-at-the-faculty-of-arts-and-social-sciences-fasos" tabindex="-1">&quot;Machines of Knowledge&quot; course at the Faculty of Arts and Social Sciences (FASoS) <a class="header-anchor" href="#machines-of-knowledge-course-at-the-faculty-of-arts-and-social-sciences-fasos" aria-label="Permalink to &quot;&quot;Machines of Knowledge&quot; course at the Faculty of Arts and Social Sciences (FASoS)&quot;">​</a></h2><p>The course <a href="https://curriculum.maastrichtuniversity.nl/nl/meta/491216/machines-knowledge" target="_blank" rel="noreferrer">Machines of Knowledge</a>, taught in the MA Digital Cultures programme, introduces students to the transformation of the World Wide Web from an information space with a limited number of content creators to a complex network of dynamic knowledge sites to which all users can (potentially) contribute. In terms of methods, the course introduces students to the basic of distant reading. Students learn how to collect their own text corpus from the web and how to analyse it with text analysis software that highlights word frequencies, word co-occurences and narrative trends. We explore different data sets to critically reflect on how users interact online, how trending topics arise, and how digital communities are formed. The technical skills acquired in this course prepare students for further studies and research, but are equally useful for professional careers in the media and (social media) marketing.</p>',7)]))}const f=t(i,[["render",s]]);export{m as __pageData,f as default};
